{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pdftotext.PDF at 0x1106fa120>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdftotext\n",
    "\n",
    "# Load your PDF\n",
    "with open(\"../src/data/tool/test.pdf\", \"rb\") as f:\n",
    "    pdf = pdftotext.PDF(f)\n",
    "\n",
    "# How many pages?\n",
    "print(len(pdf))\n",
    "\n",
    "# Iterate over all the pages\n",
    "for page in pdf:\n",
    "    print(page)\n",
    "\n",
    "# Read some individual pages\n",
    "print(pdf[0])\n",
    "print(pdf[1])\n",
    "\n",
    "# Read all the text into one string\n",
    "print(\"\\n\\n\".join(pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                           An annotation scheme for citation function\\n                        Simone Teufel               Advaith Siddharthan                           Dan Tidhar\\n                            Natural Language and Information Processing Group\\n                                                  Computer Laboratory\\n                                        Cambridge University, CB3 0FD, UK\\n      {Simone.Teufel,Advaith.Siddharthan,Dan.Tidhar}@cl.cam.ac.uk\\n                         Abstract                                     Li and Abe 96                   Brown et al. 90a          Church and Gale 91\\n                                                                                    Resnik 95                         Rose et al. 90\\n      We study the interplay of the discourse struc-\\n      ture of a scientific argument with formal ci-                                                                                  Dagan et al. 94\\n      tations. One subproblem of this is to clas-                   Hindle 93                Nitta and Niwa 94      Dagan et al 93\\n      sify academic citations in scientific articles ac-\\n      cording to their rhetorical function, e.g., as a\\n      rival approach, as a part of the solution, or\\n      as a flawed approach that justifies the cur-\\n                                                                    Hindle 90\\n      rent research. Here, we introduce our anno-                                                    Pereira et al. 93\\n      tation scheme with 12 categories, and present                       His notion of similarity\\n                                                                          seems to agree with our              Following Pereira et al, we measure\\n      an agreement study.                                                 intuitions in many cases,            word similarity by the relative entropy\\n                                                                          but it is not clear how it           or Kulbach−Leibler (KL) distance, bet−\\n                                                                          can be used directly to\\n1 Scientific writing, discourse structure                                 construct word classes\\n                                                                                                               ween the corresponding conditional\\n                                                                                                               distributions.\\n                                                                          and corresponding\\n      and citations                                                       models of association.\\nIn recent years, there has been increasing interest in\\n                                                                                    Figure 1: A rhetorical citation map\\napplying natural language processing technologies to\\nscientific literature. The overwhelmingly large num-\\nber of papers published in fields like biology, genetics            sentences (i.e., the sentence expressing the contrast or\\nand chemistry each year means that researchers need                 continuation would be outside the CiteSeer snippet).\\ntools for information access (extraction, retrieval, sum-           We present here an approach which uses the classifica-\\nmarization, question answering etc). There is also in-              tion of citations to help provide relational information\\ncreased interest in automatic citation indexing, e.g.,              across papers.\\nthe highly successful search tools Google Scholar and                  Citations play a central role in the process of writing\\nCiteSeer (Giles et al., 1998).1 This general interest in            a paper. Swales (1990) argues that scientific writing\\nimproving access to scientific articles fits well with re-          follows a general rhetorical argumentation structure:\\nsearch on discourse structure, as knowledge about the               researchers must justify that their paper makes a con-\\noverall structure and goal of papers can guide better in-           tribution to the knowledge in their discipline. Several\\nformation access.                                                   argumentation steps are required to make this justifica-\\n   Shum (1998) argues that experienced researchers are              tion work, e.g., the statement of their specific goal in\\noften interested in relations between articles. They                the paper (Myers, 1992). Importantly, the authors also\\nneed to know if a certain article criticises another and            must relate their current work to previous research, and\\nwhat the criticism is, or if the current work is based              acknowledge previous knowledge claims; this is done\\non that prior work. This type of information is hard                with a formal citation, and with language connecting\\nto come by with current search technology. Neither                  the citation to the argument, e.g., statements of usage of\\nthe author’s abstract, nor raw citation counts help users           other people’s approaches (often near textual segments\\nin assessing the relation between articles. And even                in the paper where these approaches are described), and\\nthough CiteSeer shows a text snippet around the phys-               statements of contrast with them (particularly in the\\nical location for searchers to peruse, there is no guar-            discussion or related work sections). We argue that the\\nantee that the text snippet provides enough information             automatic recognition of citation function is interest-\\nfor the searcher to infer the relation. In fact, studies            ing for two reasons: a) it serves to build better citation\\nfrom our annotated corpus (Teufel, 1999), show that                 indexers and b) in the long run, it will help constrain\\n69% of the 600 sentences stating contrast with other                interpretations of the overall argumentative structure of\\nwork and 21% of the 246 sentences stating research                  a scientific paper.\\ncontinuation with other work do not contain the cor-                   Being able to interpret the rhetorical status of a ci-\\nresponding citation; the citation is found in preceding             tation at a glance would add considerable value to ci-\\n    1\\n      CiteSeer automatically citation-indexes all scientific ar-    tation indexes, as shown in Fig. 1. Here differences\\nticles reached by a web-crawler, making them available to           and similarities are shown between the example paper\\nsearchers via authors or keywords in the title.                     (Pereira et al., 1993) and the papers it cites, as well as\\n                                                                 80\\n                     Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 80–87,\\n                            Sydney, July 2006. c 2006 Association for Computational Linguistics\\n the papers that cite it. Contrastive links are shown in            1.   Cited source is mentioned in the introduction or\\n                                                                        discussion as part of the history and state of the\\ngrey – links to rival papers and papers the current pa-\\n                                                                        art of the research question under investigation.\\nper contrasts itself to. Continuative links are shown in\\nblack – links to papers that are taken as starting point of        2.   Cited source is the specific point of departure for\\n                                                                        the research question investigated.\\nthe current research, or as part of the methodology of\\nthe current paper. The most important textual sentence             3.   Cited source contains the concepts, definitions,\\n                                                                        interpretations used (and pertaining to the disci-\\nabout each citation could be extracted and displayed.                   pline of the citing article).\\nFor instance, we see which aspect of Hindle (1990) the\\n                                                                   4.   Cited source contains the data (pertaining to the\\nPereira et al. paper criticises, and in which way Pereira               discipline of the citing article) which are used\\net al.’s work was used by Dagan et al. (1994).                          sporadically in the article.\\n   We present an annotation scheme for citations, based\\n                                                                   5.   Cited source contains the data (pertaining to the\\non empirical work in content citation analysis, which                   discipline of the citing particle) which are used\\nfits into this general framework of scientific argument                 for comparative purposes, in tables and statistics.\\nstructure. It consists of 12 categories, which allow us            6.   Cited source contains data and material (from\\nto mark the relationships of the current paper with the                 other disciplines than citing article) which is\\ncited work. Each citation is labelled with exactly one                  used sporadically in the citing text, in tables or\\ncategory. The following top-level four-way distinction                  statistics.\\napplies:                                                           7.   Cited source contains the method used.\\n                                                                   8.   Cited source substantiated a statement or assump-\\n   • Weakness: Authors point out a weakness in cited                    tion, or points to further information.\\n      work\\n                                                                   9.   Cited source is positively evaluated.\\n   • Contrast: Authors make contrast/comparison with              10.   Cited source is negatively evaluated.\\n      cited work (4 categories)                                   11.   Results of citing article prove, verify, substantiate\\n                                                                        the data or interpretation of cited source.\\n   • Positive: Authors agree with/make use of/show\\n      compatibility or similarity with cited work (6 cat-         12.   Results of citing article disprove, put into ques-\\n                                                                        tion the data as interpretation of cited source.\\n      egories), and\\n                                                                  13.   Results of citing article furnish a new interpreta-\\n   • Neutral: Function of citation is either neutral, or                tion/explanation to the data of the cited source.\\n      weakly signalled, or different from the three func-\\n      tions stated above.\\n                                                               Figure 2: Spiegel-Rüsing’s (1977) Categories for Cita-\\n   We first turn to the point of how to classify citation      tion Motivations\\nfunction in a robust way. Later in this paper, we will\\nreport results for a human annotation experiment with\\nthree annotators.                                              particular early, basic paper, which gives the founda-\\n                                                               tion of their current subject (“paying homage to pio-\\n2 Annotation schemes for citations                             neers”). Many classification schemes for citation func-\\nIn the field of library sciences (more specifically, the       tions have been developed (Weinstock, 1971; Swales,\\nfield of Content Citation Analysis), the use of informa-       1990; Oppenheim and Renn, 1978; Frost, 1979; Chu-\\ntion from citations above and beyond simple citation           bin and Moitra, 1975), inter alia. Based on such an-\\ncounting has received considerable attention. Biblio-          notation schemes and hand-analyzed data, different in-\\nmetric measures assesses the quality of a researcher’s         fluences on citation behaviour can be determined, but\\noutput, in a purely quantitative manner, by counting           annotation in this field is usually done manually on\\nhow many papers cite a given paper (White, 2004;               small samples of text by the author, and not confirmed\\nLuukkonen, 1992) or by more sophisticated measures             by reliability studies. As one of the earliest such stud-\\nlike the h-index (Hirsch, 2005). But not all citations         ies, Moravcsik and Murugesan (1975) divide citations\\nare alike. Researchers in content citation analysis have       in running text into four dimensions: conceptual or\\nlong stated that the classification of motivations is a        operational use (i.e., use of theory vs. use of techni-\\ncentral element in understanding the relevance of the          cal method); evolutionary or juxtapositional (i.e., own\\npaper in the field. Bonzi (1982), for example, points out      work is based on the cited work vs. own work is an al-\\nthat negational citations, while pointing to the fact that     ternative to it); organic or perfunctory (i.e., work is cru-\\na given work has been noticed in a field, do not mean          cially needed for understanding of citing article or just\\nthat that work is received well, and Ziman (1968) states       a general acknowledgement); and finally confirmative\\nthat many citations are done out of “politeness” (to-          vs. negational (i.e., is the correctness of the findings\\nwards powerful rival approaches), “policy” (by name-           disputed?). They found, for example, that 40% of the\\ndropping and argument by authority) or “piety” (to-            citations were perfunctory, which casts further doubt\\nwards one’s friends, collaborators and superiors). Re-         on the citation-counting approach.\\nsearchers also often follow the custom of citing some             Other content citation analysis research which is rel-\\n                                                            81\\n evant to our work concentrates on relating textual spans       cation we have in mind. A third criterion is that they\\nto authors’ descriptions of other work. For example, in        should have some (theoretical) relation to the particu-\\nO’Connor’s (1982) experiment, citing statements (one           lar discourse structure we work with (Teufel, 1999).\\nor more sentences referring to other researchers’ work)           Our categories are as follows: One category (Weak)\\nwere identified manually. The main problem encoun-             is reserved for weakness of previous research, if it is ad-\\ntered in that work is the fact that many instances of cita-    dressed by the authors (cf. Spiegel-Rüsing’s categories\\ntion context are linguistically unmarked. Our data con-        10, 12, possibly 13). The next three categories describe\\nfirms this: articles often contain large segments, par-        comparisons or contrasts between own and other work\\nticularly in the central parts, which describe other peo-      (cf. Spiegel-Rüsing’s category 5). The difference be-\\nple’s research in a fairly neutral way. We would thus          tween them concerns whether the comparison is be-\\nexpect many citations to be neutral (i.e., not to carry        tween methods/goals (CoCoGM) or results (CoCoR0).\\nany function relating to the argumentation per se).            These two categories are for comparisons without ex-\\n   Many of the distinctions typically made in content          plicit value judgements. We use a different category\\ncitation analysis are immaterial to the task considered        (CoCo-) when the authors claim their approach is bet-\\nhere as they are too sociologically orientated, and can        ter than the cited work.\\nthus be difficult to operationalise without deep knowl-           Our interest in differences and similarities between\\nedge of the field and its participants (Swales, 1986). In      approaches stems from one possible application we\\nparticular, citations for general reference (background        have in mind (the rhetorical citation search tool). We\\nmaterial, homage to pioneers) are not part of our an-          do not only consider differences stated between the cur-\\nalytic interest here, and so are citations “in passing”,       rent work and other work, but we also mark citations if\\nwhich are only marginally related to the argumentation         they are explicitly compared and contrasted with other\\nof the overall paper (Ziman, 1968).                            work (not the current paper). This is expressed in cat-\\n   Spiegel-Rüsing’s (1977) scheme (Fig. 2) is an exam-        egory CoCoXY. It is a category not typically consid-\\nple of a scheme which is easier to operationalise than         ered in the literature, but it is related to the other con-\\nmost. In her scheme, more than one category can apply          trastive categories, and useful to us because we think\\nto a citation; for instance positive and negative evalu-       it can be exploited for search of differences and rival\\nation (category 9 and 10) can be cross-classified with         approaches.\\nother categories. Out of 2309 citations examined, 80%\\n                                                                  The next set of categories we propose concerns pos-\\nsubstantiated statements (category 8), 6% discussed\\n                                                               itive sentiment expressed towards a citation, or a state-\\nhistory or state of the art of the research area (cate-\\n                                                               ment that the other work is actively used in the cur-\\ngory 1) and 5% cited comparative data (category 5).\\n                                                               rent work (which is the ultimate praise). Like Spiegel-\\n                                                               Rüsing, we are interested in use of data and methods\\n  Category     Description\\n  Weak         Weakness of cited approach                      (her categories 4, 5, 6, 7), but we cluster different us-\\n  CoCoGM       Contrast/Comparison in Goals or Meth-           ages together and instead differentiate unchanged use\\n               ods (neutral)                                   (PUse) from use with adaptations (PModi). Work\\n  CoCoR0       Contrast/Comparison in Results (neutral)        which is stated as the explicit starting point or intellec-\\n  CoCo-        Unfavourable Contrast/Comparison (cur-          tual ancestry is marked with our category PBas (her\\n               rent work is better than cited work)\\n  CoCoXY       Contrast between 2 cited methods\\n                                                               category 2). If a claim in the literature is used to\\n  PBas         author uses cited work as starting point        strengthen the authors’ argument, this is expressed in\\n  PUse         author uses tools/algorithms/data               her category 8, and vice versa, category 11. We col-\\n  PModi        author        adapts       or      modifies     lapse these two in our category PSup. We use two\\n               tools/algorithms/data                           categories she does not have definitions for, namely\\n  PMot         this citation is positive about approach or\\n                                                               similarity of (aspect of) approach to other approach\\n               problem addressed (used to motivate work\\n               in current paper)                               (PSim), and motivation of approach used or problem\\n  PSim         author’s work and cited work are similar        addressed (PMot). We found evidence for prototypi-\\n  PSup         author’s work and cited work are compat-        cal use of these citation functions in our texts. How-\\n               ible/provide support for each other             ever, we found little evidence for her categories 12 or\\n  Neut         Neutral description of cited work, or not\\n                                                               13 (disproval or new interpretation of claims in cited\\n               enough textual evidence for above cate-\\n               gories or unlisted citation function            literature), and we decided against a “state-of-the-art”\\n                                                               category (her category 1), which would have been in\\n Figure 3: Our annotation scheme for citation function         conflict with our PMot definition in many cases.\\n                                                                  Our fourteenth category, Neut, bundles truly neutral\\n   Our scheme (given in Fig. 3) is an adaptation of the        descriptions of other researchers’ approaches with all\\nscheme in Fig. 2, which we arrived at after an analysis        those cases where the textual evidence for a citation\\nof a corpus of scientific articles in computational lin-       function was not enough to warrant annotation of that\\nguistics. We tried to redefine the categories such that        category, and all other functions for which our scheme\\nthey should be reasonably reliably annotatable; at the         did not provide a specific category. As stated above, we\\nsame time, they should be informative for the appli-           do in fact expect many of our citations to be neutral.\\n                                                            82\\n    Citation function is hard to annotate because it in          research as starting point, as intellectual ancestry, i.e.\\nprinciple requires interpretation of author intentions          PBas) and simply using it (PUse). In principle, one\\n(what could the author’s intention have been in choos-          would hope that annotation of all usage/positive cate-\\ning a certain citation?). Typical results of earlier cita-      gories (starting with P), if clustered together, should re-\\ntion function studies are that the sociological aspect of       sult in higher agreement (as they are similar, and as the\\nciting is not to be underestimated. One of our most fun-        resulting scheme has fewer distinctions). We would ex-\\ndamental ideas for annotation is to only mark explicitly        pect this to be the case in general, but as always, cases\\nsignalled citation functions. Our guidelines explicitly         exist where a conflict between a contrast (CoCo) and a\\nstate that a general linguistic phrase such as “better”         change to a method (PModi) occur:\\nor “used by us” must be present, in order to increase\\nobjectivity in finding citation function. Annotators are               In contrast to McCarthy, Kay and Kiraz,\\nencouraged to point to textual evidence they have for                  we combine the three components into a sin-\\nassigning a particular function (and are asked to type                 gle projection.               (0006044, S-182)\\nthe source of this evidence into the annotation tool for           The markable units in our scheme are a) all full cita-\\neach citation). Categories are defined in terms of cer-         tions (as recognized by our automatic citation proces-\\ntain objective types of statements (e.g., there are 7 cases     sor on our corpus), and b) all names of authors of cited\\nfor PMot). Annotators can use general text interpreta-          papers anywhere in running text outside of a formal\\ntion principles when assigning the categories, but are          citation context (i.e., without date). Our citation pro-\\nnot allowed to use in-depth knowledge of the field or           cessor recognizes these latter names after parsing the\\nof the authors.                                                 citation list an marks them up. This is unusual in com-\\n   There are other problematic aspects of the annota-           parison to other citation indexers, but we believe these\\ntion. Some concern the fact that authors do not al-             names function as important referents comparable in\\nways state their purpose clearly. For instance, several         importance to formal citations. In principle, one could\\nearlier studies found that negational citations are rare        go even further as there are many other linguistic ex-\\n(Moravcsik and Murugesan, 1975; Spiegel-Rüsing,                pressions by which the authors could refer to other peo-\\n1977); MacRoberts and MacRoberts (1984) argue that              ple’s work: pronouns, abbreviations such as “Mueller\\nthe reason for this is that they are potentially politically    and Sag (1990), henceforth M & S”, and names of ap-\\ndangerous, and that the authors go through lengths to           proaches or theories which are associated with partic-\\ndiffuse the impact of negative references, hiding a neg-        ular authors. If we could mark all of these up auto-\\native point behind insincere praise, or diffusing the           matically (which is not technically possible), annota-\\nthrust of criticism with perfunctory remarks. In our            tion would become less difficult to decide, but techni-\\ndata we found ample evidence of this effect, illustrated        cal difficulty prevent us from recognizing these other\\nby the following example:                                       cases automatically. As a result, in these contexts it is\\n       Hidden Markov Models (HMMs) (Huang                       impossible to annotate citation function directly on the\\n       et al. 1990) offer a powerful statistical ap-            referent, which sometimes causes problems. Because\\n       proach to this problem, though it is unclear             this means that annotators have to consider non-local\\n       how they could be used to recognise the units            context, one markable may have different competing\\n       of interest to phonologists. (9410022, S-24)2            contexts with different potential citation functions, and\\n                                                                problems about which context is “stronger” may oc-\\n   It is also sometimes extremely hard to distinguish           cur. We have rules that context is to be constrained to\\nusage of a method from statements of similarity be-             the paragraph boundary, but for some categories paper-\\ntween a method and the own method. This happens                 wide information is required (e.g., for PMot, we need\\nin cases where authors do not want to admit they are            to know that a praised approach is used by the authors,\\nusing somebody else’s method:                                   information which may not be local in the paragraph).\\n       The same test was used in Abney and Light                   Appendix A gives unambiguous example cases\\n       (1999).                      (0008020, S-151)            where the citation function can be decided on the ba-\\n       Unification of indices proceeds in the same              sis of the sentence alone, but Fig. 4 shows a more typ-\\n       manner as unification of all other typed                 ical example where more context is required to inter-\\n       feature structures (Carpenter 1992).                     pret the function. The evaluation of the citation Hin-\\n                                     (0008023, S-87)            dle (1990) is contrastive; the evaluative statement is\\n                                                                found 4 sentences after the sentence containing the ci-\\n   In this case, our annotators had to choose between           tation3 . It consists of a positive statement (agreement\\ncategories PSim and PUse.                                       with authors’ view), followed by a weakness, under-\\n   It can also be hard to distinguish between continu-          lined, which is the chosen category. This is marked on\\nation of somebody’s research (i.e., taking somebody’s           the nearest markable (Hindle, 3 sentences after the ci-\\n    2\\n                                                                tation).\\n      In all corpus examples, numbers in brackets correspond\\n                                                                    3\\nto the official Cmp lg archive number, “S-” numbers to sen-           In Fig. 4, markables are shown in boxes, evaluative state-\\ntence numbers according to our preprocessing.                   ments underlined, and referents in bold face.\\n                                                             83\\n   S-5 Hindle (1990)/Neut proposed dealing with the             overlap of citing and cited authors. The citation pro-\\n  sparseness problem by estimating the likelihood of un-       cessor developped in our group (Ritchie et al., 2006)\\n  seen events from that of “similar” events that have been     achieves high accuracy for this task (96% of citations\\n  seen.                                                        recognized, provided the reference list was error-free).\\n  S-6 For instance, one may estimate the likelihood of a\\n  particular direct object for a verb from the likelihoods     On average, our papers contain 26.8 citation instances\\n  of that direct object for similar verbs.                     in running text4 .\\n  S-7 This requires a reasonable definition of verb simi-\\n  larity and a similarity estimation method.                   4 Human Annotation: results\\n  S-8 In Hindle/Weak ’s proposal, words are similar\\n  if we have strong statistical evidence that they tend to     In order to machine learn citation function, we are\\n  participate in the same events.                              in the process of creating a corpus of scientific arti-\\n  S-9 His notion of similarity seems to agree with our in-     cles with human annotated citations, according to the\\n  tuitions in many cases, but it is not clear how it can be    scheme discussed before. Here we report preliminary\\n  used directly to construct word classes and correspond-\\n                                                               results with that scheme, with three annotators who are\\n  ing models of association.                    (9408011)\\n                                                               developers of the scheme.\\n  Figure 4: Annotation example: influence of context              In our experiment, the annotators independently an-\\n                                                               notated 26 conference articles with this scheme, on the\\n                                                               basis of guidelines which were frozen once annotation\\n    A naive view on this annotation scheme could con-          started5 . The data used for the experiment contained a\\nsider the first two sets of categories in our scheme as        total of 120,000 running words and 548 citations.\\n“negative” and the third set of categories “positive”.            The relative frequency of each category observed in\\nThere is indeed a sentiment aspect to the interpretation       the annotation is listed in Fig. 5. As expected, the dis-\\nof citations, due to the fact that authors need to make        tribution is very skewed, with more than 60% of the\\na point in their paper and thus have a stance towards          citations of category Neut.6 What is interesting is the\\ntheir citations. But this is not the whole story: many         relatively high frequency of usage categories (PUse,\\nof our “positive” categories are more concerned with           PModi, PBas) with a total of 18.9%. There is\\ndifferent ways in which the cited work is useful to the        a relatively low frequency of clearly negative cita-\\ncurrent work (which aspect of it is used, e.g., just a         tions (Weak, CoCoR-, total of 4.1%), whereas the\\ndefinition or the entire solution?), and many of the con-      neutral–contrastive categories (CoCoGM, CoCoR0,\\ntrastive statements have no negative connotation at all        CoCoXY) are slightly more frequent at 7.6%. This\\nand simply state a (value-free) difference between ap-         is in concordance with earlier annotation experiments\\nproaches. However, if one looks at the distribution of         (Moravcsik and Murugesan, 1975; Spiegel-Rüsing,\\npositive and negative adjectives around citations, one         1977).\\nnotices a (non-trivial) connection between our task and           We reached an inter-annotator agreement of K=.72\\nsentiment classification.                                      (n=12;N=548;k=3)7. This is comparable to aggreement\\n    There are written guidelines of 25 pages, which in-        on other discourse annotation tasks such as dialogue\\nstruct the annotators to only assign one category per          act parsing and Argumentative Zoning (Teufel et al.,\\ncitation, and to skim-read the paper before annotation.        1999). We consider the agreement quite good, consid-\\nThe guidelines provide a decision tree and give deci-          ering the number of categories and the difficulties (e.g.,\\nsion aids in systematically ambiguous cases, but sub-          non-local dependencies) of the task.\\njective judgement of the annotators is nevertheless nec-          The annotators are obviously still disagreeing on\\nessary to assign a single tag in an unseen context. We         some categories. We were wondering to what de-\\nimplemented an annotation tool based on XML/XSLT               gree the fine granularity of the scheme is a prob-\\ntechnology, which allows us to use any web browser to          lem. When we collapsed the obvious similar cat-\\ninteractively assign one of the 12 tags (presented as a        egories (all P categories into one category, and\\npull-down list) to each citation.                              all CoCo categories into another) to give four top\\n                                                               level categories (Weak, Positive, Contrast,\\n                                                               Neutral), this only raised kappa to 0.76. This\\n3 Data\\n                                                                   4\\n                                                                     As opposed to reference list items, which are fewer.\\nThe data we used came from the CmpLg (Computation                  5\\n                                                                     The development of the scheme was done with 40+ dif-\\nand Language archive; 320 conference articles in com-          ferent articles.\\nputational linguistics). The articles are in XML format.           6\\n                                                                     Spiegel-Rüsing found that out of 2309 citations she ex-\\nHeadlines, titles, authors and reference list items are        amined, 80% substantiated statements.\\n                                                                   7\\nautomatically marked up with the corresponding tags.                 Following Carletta (1996), we measure agreement in\\nReference lists are parsed, and cited authors’ names           Kappa, which follows the formula K = P (A)−P        (E)\\n                                                                                                             1−P (E)\\n                                                                                                                       where\\nare identified. Our citation parser then applies regu-         P(A) is observed, and P(E) expected agreement. Kappa\\n                                                               ranges between -1 and 1. K=0 means agreement is only as\\nlar patterns and finds citations and other occurrences of      expected by chance. Generally, Kappas of 0.8 are considered\\nthe names of cited authors (without a date) in running         stable, and Kappas of .69 as marginally stable, according to\\ntext and marks them up. Self-citations are detected by         the strictest scheme applied in the field.\\n                                                            84\\n    Neut     PUse     CoCoGM       PSim      Weak     CoCoXY       PMot     PModi     PBas    PSup      CoCo-      CoCoR0\\n  62.7%    15.8%       3.9%       3.8%      3.1%      2.9%       2.2%      1.6%     1.5%     1.1%      1.0%        0.8%\\n                                         Figure 5: Distribution of the categories\\n              Weak    CoCo-    CoCoGM       CoCoR0    CoCoXY      PUse    PBas   PModi    PMot    PSim     PSup    Neut\\n  Weak          5                                                                                                    3\\n  CoCo-                  1         3\\n  CoCoGM                           23                                                                3\\n  CoCoR0                                        4\\n  CoCoXY                                                  1\\n  PUse                                                              86      6                        2       1      12\\n  PBas                                                                      3                                        2\\n  PModi                                                                             3\\n  PMot                                                                                      13                       4\\n  PSim                                                              3                               20               5\\n  PSup                   1                                          2                                        1\\n  Neut          6                  10           6         4         17      1               6        4              287\\n                                 Figure 6: Confusion matrix between two annotators\\npoints to the fact that most of our annotators disagreed                          Weakness      Positive    Neutral\\nabout whether to assign a more informative category                  Weakness          9           1           12\\nor Neut, the neutral fall-back category. Unfortunately,              Positive                     140           13\\nKappa is only partially sensitive to such specialised dis-           Neutral           4           30          339\\nagreements. While it will reward agreement with in-\\nfrequent categories more than agreement with frequent          Figure 7: Confusion matrix between two annotators;\\ncategories, it nevertheless does not allow us to weight        categories collapsed to reflect sentiment\\ndisagreements we care less about (Neut vs more in-\\nformative category) less than disagreements we do care\\na lot about (informative categories which are mutually         have only one case of confusion between positive and\\nexclusive, such as Weak and PSim).                             negative references to cited work. The vast majority of\\n   Fig. 6 shows a confusion matrix between the two an-         disagreements reflects genuine ambiguity as to whether\\nnotators who agreed most with each other. This again           the authors were trying to stay neutral or express a sen-\\npoints to the fact that a large proportion of the confu-       timent.\\nsion involves an informative category and Neut. The\\nissue with Neut and Weak is a point at hand: au-                            Distinction               Kappa\\nthors seem to often (deliberately or not) mask their in-                    PMot v. all others           .790\\ntended citation function with seemingly neutral state-                      CoCoGM v. all others         .765\\nments. Many statements of weakness of other ap-                             PUse v. all others           .761\\nproaches were stated in such caged terms that our anno-                     CoCoR0 v. all others         .746\\ntators disagreed about whether the signals given were                       Neut v. all others           .742\\n“explicit” enough.                                                          PSim v. all others           .649\\n   While our focus is not sentiment analysis, it is pos-                    PModi v. all others          .553\\nsible to conflate our 12 categories into three: positive,                   CoCoXY v. all others         .553\\nweakness and neutral by the following mapping:                              Weak v. all others           .522\\n                                                                            CoCo- v. all others          .462\\n                                                                            PBas v. all others           .414\\n                          Old Categories    New Category\\n                                                                            PSup v. all others           .268\\n                           Weak, CoCo-      Negative\\n  PMot, PUse, PBas, PModi, PSim, PSup       Positive\\n     CoCoGM, CoCoR0, CoCoXY, Neut           Neutral                     Figure 8: Distinctiveness of categories\\n   Thus negative contrasts and weaknesses are grouped             In an attempt to determine how well each cate-\\ninto Negative, while neutral contrasts are grouped             gory was defined, we created artificial splits of the\\ninto Neutral. All the positive classes are conflated           data into binary distinctions: each category versus a\\ninto Positive. This resulted in kappa=0.75 for three           super-category consisting of all the other collapsed cat-\\nannotators.                                                    egories. The kappas measured on these datasets are\\n   Fig. 7 shows the confusion matrix between two an-           given in Fig. 8. The higher they are, the better the anno-\\nnotators for this sentiment classification. Fig. 7 is par-     tators could distinguish the given category from all the\\nticularly instructive, because it shows that annotators        other categories. We can see that out of the informa-\\n                                                           85\\n tive categories, four are defined at least as well as the           tasks: The kappa statistic. Computational Linguistics,\\noverall distinction (i.e. above the line in Fig. 8: PMot,           22(2):249–254.\\nPUse, CoCoGM and CoCoR0. This is encouraging,                    Daryl E. Chubin and S. D. Moitra. 1975. Content analysis\\nas the application of citation maps is almost entirely              of references: Adjunct or alternative to citation counting?\\n                                                                    Social Studies of Science, 5(4):423–441.\\ncentered around usage and contrast. However, the se-\\n                                                                 Carolyn O. Frost. 1979. The use of citations in literary re-\\nmantics of some categories are less well-understood by              search: A preliminary classification of citation functions.\\nour annotators: in particular PSup (where the difficulty            Library Quarterly, 49:405.\\nlies in what an annotator understands as “mutual sup-            C. Lee Giles, Kurt D. Bollacker, and Steve Lawrence. 1998.\\nport” of two theories), and (unfortunately) PBas. The               Citeseer: An automatic citation indexing system. In Pro-\\nproblem with PBas is that its distinction from PUse is              ceedings of the Third ACM Conference on Digital Li-\\n                                                                    braries, pages 89–98.\\nbased on subjective judgement of whether the authors\\n                                                                 Jorge E. Hirsch. 2005. An index to quantify an individ-\\nuse a part of somebody’s previous work, or base them-               ual’s scientific research output. Proceedings of the Na-\\nselves entirely on this previous work (i.e., see them-              tional Academy of Sciences of the United Stated of Amer-\\nselves as following in the same intellectual framework).            ica (PNAS), 102(46).\\nAnother problem concerns the low distinctivity for the           Terttu Luukkonen. 1992. Is scientists’ publishing behaviour\\nclearly negative categories CoCo- and Weak. This is                 reward-seeking? Scientometrics, 24:297–319.\\nin line with MacRoberts and MacRoberts’ hypothesis               Michael H. MacRoberts and Barbara R. MacRoberts. 1984.\\nthat criticism is often hedged and not clearly lexically            The negational reference: Or the art of dissembling. So-\\n                                                                    cial Studies of Science, 14:91–94.\\nsignalled, which makes it more difficult to reliably an-\\n                                                                 Michael J. Moravcsik and Poovanalingan Murugesan. 1975.\\nnotate such citations.                                              Some results on the function and quality of citations. So-\\n                                                                    cial Studies of Science, 5:88–91.\\n5 Conclusion                                                     Greg Myers. 1992. In this paper we report...—speech acts\\n                                                                    and scientific facts. Journal of Pragmatics, 17(4):295–\\nWe have described a new task: human annotation of                   313.\\ncitation function, a phenomenon which we believe to              John O’Connor. 1982. Citing statements: Computer recogni-\\nbe closely related to the overall discourse structure of            tion and use to improve retrieval. Information Processing\\n                                                                    and Management, 18(3):125–131.\\nscientific articles. Our annotation scheme concentrates\\n                                                                 Charles Oppenheim and Susan P. Renn. 1978. Highly cited\\non contrast, weaknesses of other work, similarities be-             old papers and the reasons why they continue to be cited.\\ntween work and usage of other work. One of its prin-                JASIS, 29:226–230.\\nciples is the fact that relations are only to be marked if       Anna Ritchie, Simone Teufel, and Steven Robertson. 2006.\\nthey are explicitly signalled. Here, we report positive             Creating a test collection for citation-based IR experi-\\nresults in terms of interannotator agreement.                       ments. In Proceedings of HLT-06.\\n   Future work on the annotation scheme will concen-             Simon Buckingham Shum. 1998. Evolving the web for sci-\\n                                                                    entific knowledge: First steps towards an “HCI knowledge\\ntrate on improving guidelines for currently suboptimal\\n                                                                    web”. Interfaces, British HCI Group Magazine, 39:16–21.\\ncategories, and on measuring intra-annotator agree-              Ina Spiegel-Rüsing. 1977. Bibliometric and content analy-\\nment and inter-annotator agreement with naive annota-               sis. Social Studies of Science, 7:97–113.\\ntors. We are also currently investigating how well our           John Swales. 1986. Citation analysis and discourse analysis.\\nscheme will work on text from a different discipline,               Applied Linguistics, 7(1):39–56.\\nnamely chemistry. Work on applying machine learning              John Swales, 1990. Genre Analysis: English in Academic\\ntechniques for automatic citation classification is cur-            and Research Settings. Chapter 7: Research articles in En-\\nrently underway (Teufel et al., 2006); the agreement                glish, pages 110–176. Cambridge University Press, Cam-\\n                                                                    bridge, UK.\\nof one annotator and the system is currently K=.57,\\n                                                                 Simone Teufel, Jean Carletta, and Marc Moens. 1999. An\\nleaving plenty of room for improvement in comparison                annotation scheme for discourse-level argumentation in re-\\nwith the human annotation results presented here.                   search articles. In Proceedings of the Ninth Meeting of the\\n                                                                    European Chapter of the Association for Computational\\n6 Acknowledgements                                                  Linguistics (EACL-99), pages 110–117.\\n                                                                 Simone Teufel, Advaith Siddharthan, and Dan Tidhar. 2006.\\nThis work was funded by the EPSRC projects                          Automatic classification of citation function. In Proceed-\\nCITRAZ (GR/S27832/01, “Rhetorical Citation Maps                     ings of EMNLP-06.\\n                                                                 Simone Teufel. 1999. Argumentative Zoning: Information\\nand Domain-independent Argumentative Zoning”) and\\n                                                                    Extraction from Scientific Text. Ph.D. thesis, School of\\nSCIBORG (EP/C010035/1, “Extracting the Science                      Cognitive Science, University of Edinburgh, UK.\\nfrom Scientific Publications”).                                  Melvin Weinstock. 1971. Citation indexes. In Encyclopedia\\n                                                                    of Library and Information Science, volume 5, pages 16–\\n                                                                    40. Dekker, New York, NY.\\nReferences                                                       Howard D. White. 2004. Citation analysis and discourse\\n                                                                    analysis revisited. Applied Linguistics, 25(1):89–116.\\nSusan Bonzi. 1982. Characteristics of a literature as predic-    John M. Ziman. 1968. Public Knowledge: An Essay Con-\\n   tors of relatedness between cited and citing works. JASIS,       cerning the Social Dimensions of Science. Cambridge\\n   33(4):208–216.                                                   University Press, Cambridge, UK.\\nJean Carletta. 1996. Assessing agreement on classification\\n                                                              86\\n A  Annotation examples\\n Weak   However, Koskenniemi himself understood that his initial implementation had signif-\\n        icant limitations in handling non-concatenative morphotactic processes.\\n                                                                                 (0006044, S-4)\\n CoCoGM The goals of the two papers are slightly different: Moore ’s approach is designed to\\n        reduce the total grammar size (i.e., the sum of the lengths of the productions), while\\n        our approach minimizes the number of productions.\\n                                                                                (0008021, S-22)\\n CoCoR0 This is similar to results in the literature (Ramshaw and Marcus 1995).\\n                                                                               (0008022, S-147)\\n CoCo-  For the Penn Treebank, Ratnaparkhi (1996) reports an accuracy of 96.6% using the\\n        Maximum Entropy approach, our much simpler and therefore faster HMM approach\\n        delivers 96.7%.                                                        (0003055, S-156)\\n CoCoXY Unlike previous approaches (Ellison 1994, Walther 1996), Karttunen ’s approach\\n        is encoded entirely in the finite state calculus, with no extra-logical procedures for\\n        counting constraint violations.                                          (0006038, S-5)\\n PBas   Our starting point is the work described in Ferro et al. (1999) , which used a fairly\\n        small training set.                                                     (0008004, S-11)\\n PUse   In our application, we tried out the Learning Vector Quantization (LVQ) (Kohonen et\\n        al. 1996).                                                             (0003060, S-105)\\n PModi  In our experiments, we have used a conjugate-gradient optimization program adapted\\n        from the one presented in Press et al.                                  (0008028, S-72)\\n PMot   It has also been shown that the combined accuracy of an ensemble of multiple clas-\\n        sifiers is often significantly greater than that of any of the individual classifiers that\\n        make up the ensemble (e.g., Dietterich (1997)).                          (0005006, S-9)\\n PSim   Our system is closely related to those proposed in Resnik (1997) and Abney and\\n        Light (1999).                                                           (0008020, S-24)\\n PSup   In all experiments the SVM Light system outperformed other learning algorithms,\\n        which confirms Yang and Liu ’s (1999) results for SVMs fed with Reuters data.\\n                                                                               (0003060, S-141)\\n Neut   The cosine metric and Jaccard’s coefficient are commonly used in information re-\\n        trieval as measures of association (Salton and McGill 1983).            (0001012, S-29)\\n                                                      87\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
